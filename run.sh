export NEPTUNE_PROJECT="thanhhau097/lecr"
export NEPTUNE_API_TOKEN="eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlMTRjM2ExOC1lYTA5LTQwODctODMxNi1jZjEzMjdlMjkxYTgifQ=="
export CUDA_VISIBLE_DEVICES=1

# # -------------------------- LAYOUT:XLA:DEFAULT --------------------------
# python train.py --do_train=true --do_eval=true --do_predict=true --per_device_train_batch_size=1 --per_device_eval_batch_size=1 --learning_rate=4e-3 --warmup_ratio=0.1 --lr_scheduler_type=cosine --save_strategy=steps --save_steps=2000 --eval_steps=2000 --evaluation_strategy=steps --logging_strategy=steps --logging_steps=200 --save_total_limit=2 --load_best_model_at_end=True --optim=adamw_torch --weight_decay=1e-5 --num_train_epochs=1000 --metric_for_best_model=eval_kendalltau --greater_is_better=True --dataloader_num_workers=8 --max_grad_norm=1.0 --data_type=layout --source=xla --search=default --overwrite_output_dir=True --output_dir=./outputs_xla_default/ --report_to=neptune --load_best_model_at_end=True --hidden_channels=256,256 --fp16 --dropout=0.2 --gat_dropout=0.2 --op_embedding_dim=16 --norm=graph --max_configs=64 --use_standard_scaler --data_folder ./data/npz_all_pad/npz

# # -------------------------- LAYOUT:XLA:RANDOM ---------------------------
# python train.py --do_train=true --do_eval=true --do_predict=true --per_device_train_batch_size=1 --per_device_eval_batch_size=1 --learning_rate=4e-3 --warmup_ratio=0.1 --lr_scheduler_type=cosine --save_strategy=steps --save_steps=4000 --eval_steps=4000 --evaluation_strategy=steps --logging_strategy=steps --logging_steps=200 --save_total_limit=2 --load_best_model_at_end=True --optim=adamw_torch --weight_decay=1e-5 --num_train_epochs=1000 --metric_for_best_model=eval_kendalltau --greater_is_better=True --dataloader_num_workers=8 --max_grad_norm=1.0 --data_type=layout --source=xla --search=random --overwrite_output_dir=True --output_dir=./outputs_xla_random/ --report_to=neptune --load_best_model_at_end=True --hidden_channels=256,256 --fp16 --dropout=0.2 --gat_dropout=0.2 --op_embedding_dim=16 --use_standard_scaler --data_folder ./data/npz_all_pad/npz

# # -------------------------- LAYOUT:NLP:DEFAULT --------------------------
# python train.py --do_train=true --do_eval=true --do_predict=true --per_device_train_batch_size=1 --per_device_eval_batch_size=1 --learning_rate=4e-3 --warmup_ratio=0.1 --lr_scheduler_type=cosine --save_strategy=steps --save_steps=12000 --eval_steps=12000 --evaluation_strategy=steps --logging_strategy=steps --logging_steps=200 --save_total_limit=2 --load_best_model_at_end=True --optim=adamw_torch --weight_decay=1e-5 --num_train_epochs=1000 --metric_for_best_model=eval_kendalltau --greater_is_better=True --dataloader_num_workers=8 --max_grad_norm=1.0 --data_type=layout --source=nlp --search=default --overwrite_output_dir=True --output_dir=./outputs_nlp_default/ --report_to=neptune --load_best_model_at_end=True --hidden_channels=256,256 --fp16 --dropout=0.2 --gat_dropout=0.2 --op_embedding_dim=16 --data_folder ./data/npz_all_pad/npz # --select_close_runtimes
# # --filter_random_configs and mix data
# python train.py --do_train=true --do_eval=true --do_predict=true --per_device_train_batch_size=1 --per_device_eval_batch_size=1 --learning_rate=4e-3 --warmup_ratio=0.1 --lr_scheduler_type=cosine --save_strategy=steps --save_steps=12000 --eval_steps=12000 --evaluation_strategy=steps --logging_strategy=steps --logging_steps=200 --save_total_limit=2 --load_best_model_at_end=True --optim=adamw_torch --weight_decay=1e-5 --num_train_epochs=1000 --metric_for_best_model=eval_kendalltau --greater_is_better=True --dataloader_num_workers=8 --max_grad_norm=1.0 --data_type=layout --source=nlp --search=mix --overwrite_output_dir=True --output_dir=./outputs_nlp_mix_default/ --report_to=neptune --load_best_model_at_end=True --hidden_channels=256,256 --fp16 --dropout=0.2 --gat_dropout=0.2 --op_embedding_dim=16 --filter_random_configs --data_folder ./data/npz_all_pad/npz # --select_close_runtimes

# # -------------------------- LAYOUT:NLP:RANDOM ---------------------------
# python train.py --do_train=true --do_eval=true --do_predict=true --per_device_train_batch_size=1 --per_device_eval_batch_size=1 --learning_rate=4e-3 --warmup_ratio=0.1 --lr_scheduler_type=cosine --save_strategy=steps --save_steps=12000 --eval_steps=12000 --evaluation_strategy=steps --logging_strategy=steps --logging_steps=200 --save_total_limit=2 --load_best_model_at_end=True --optim=adamw_torch --weight_decay=1e-5 --num_train_epochs=1000 --metric_for_best_model=eval_kendalltau --greater_is_better=True --dataloader_num_workers=8 --max_grad_norm=1.0 --data_type=layout --source=nlp --search=random --overwrite_output_dir=True --output_dir=./outputs_nlp_random/ --report_to=neptune --load_best_model_at_end=True --hidden_channels=256,256 --fp16 --dropout=0.2 --gat_dropout=0.2 --op_embedding_dim=16 --data_folder ./data/npz_all_pad/npz # --select_close_runtimes

# # ------------------------------- TILE:XLA -------------------------------
# python train.py --do_train --do_eval --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --learning_rate 1e-4 --warmup_ratio 0.01 --lr_scheduler_type cosine --save_strategy epoch --evaluation_strategy epoch --logging_strategy steps --logging_steps 200 --save_total_limit 2 --load_best_model_at_end True --optim adamw_torch --weight_decay 1e-2 --num_train_epochs 50 --metric_for_best_model eval_score_tile_mean --greater_is_better=True --dataloader_num_workers=8 --max_grad_norm=1.0 --overwrite_output_dir=True --output_dir ./outputs_tile/ --report_to neptune --data_folder ./data/npz_all_pad/npz


# COMMANDS FROM EDUARDO
# python train.py --do_train=true --do_eval=true --do_predict=true --per_device_train_batch_size=1 --per_device_eval_batch_size=1 --learning_rate=1e-3 --warmup_ratio=0.05 --lr_scheduler_type=cosine --save_strategy=steps --save_steps=12000 --eval_steps=12000 --evaluation_strategy=steps --logging_strategy=steps --logging_steps=200 --save_total_limit=2 --load_best_model_at_end=True --optim=adamw_torch --weight_decay=1e-5 --num_train_epochs=1000 --metric_for_best_model=eval_kendalltau --greater_is_better=True --dataloader_num_workers=8 --max_grad_norm=1.0 --data_type=layout --source=nlp --search=default --overwrite_output_dir=True --output_dir=./outputs_nlp_default --report_to=neptune --load_best_model_at_end=True --hidden_channels=256,256 --fp16 --dropout=0.2 --gat_dropout=0.2 --op_embedding_dim=16 --max_configs=128 --select_close_runtimes=false --use_cross_attn=true --data_folder ./data/npz_all_pad/npz


# FINETUNE ON SPECIFIC VALIDATION/TEST FILES
python train.py --do_train=true --do_eval=true --do_predict=true --per_device_train_batch_size=1 --per_device_eval_batch_size=1 --learning_rate=1e-3 --warmup_ratio=0.05 --lr_scheduler_type=cosine --save_strategy=steps --save_steps=1000 --eval_steps=1000 --evaluation_strategy=steps --logging_strategy=steps --logging_steps=200 --save_total_limit=2 --load_best_model_at_end=True --optim=adamw_torch --weight_decay=1e-5 --num_train_epochs=1000 --metric_for_best_model=eval_kendalltau --greater_is_better=True --dataloader_num_workers=8 --max_grad_norm=1.0 --data_type=layout --source=nlp --search=default --overwrite_output_dir=True --output_dir=./outputs_nlp_default_finetune --report_to=neptune --load_best_model_at_end=True --hidden_channels=256,256 --fp16 --dropout=0.2 --gat_dropout=0.2 --op_embedding_dim=16 --max_configs=128 --select_close_runtimes=false --use_cross_attn=true --data_folder ./data/npz_all_pad/npz --resume ./outputs_nlp_default/checkpoint-180000/pytorch_model.bin --valid_file_names bert_en_cased_L-12_H-768_A-12_batch_size_16_test.npz
