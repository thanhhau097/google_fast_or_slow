python train.py --do_train=false --do_eval=true --per_device_train_batch_size=1 --per_device_eval_batch_size=1 --learning_rate=4e-3 --warmup_ratio=0.1 --lr_scheduler_type=cosine --save_strategy=steps --save_steps=2000 --eval_steps=2000 --evaluation_strategy=steps --logging_strategy=steps --logging_steps=200 --save_total_limit=2 --load_best_model_at_end=True --optim=adamw_torch --weight_decay=1e-5 --num_train_epochs=1000 --metric_for_best_model=eval_kendalltau --greater_is_better=True --dataloader_num_workers=4 --max_grad_norm=1.0 --data_type=layout --source=xla_pruned --search=default --overwrite_output_dir=True --output_dir=./outputs_xla_default/ --report_to=none --load_best_model_at_end=True --hidden_channels=256,256 --fp16 --dropout=0.2 --gat_dropout=0.2 --resume=/home/edu/code/google_fast_or_slow/outputs_xla_default/checkpoint-16000/pytorch_model.bin;

# python train.py --do_train=true --do_eval=true --per_device_train_batch_size=1 --per_device_eval_batch_size=1 --learning_rate=4e-3 --warmup_ratio=0.1 --lr_scheduler_type=cosine --save_strategy=steps --save_steps=2000 --eval_steps=2000 --evaluation_strategy=steps --logging_strategy=steps --logging_steps=200 --save_total_limit=2 --load_best_model_at_end=True --optim=adamw_torch --weight_decay=1e-5 --num_train_epochs=1000 --metric_for_best_model=eval_kendalltau --greater_is_better=True --dataloader_num_workers=4 --max_grad_norm=1.0 --data_type=layout --source=xla_pruned --search=random --overwrite_output_dir=True --output_dir=./outputs_xla_random/ --report_to=none --load_best_model_at_end=True --hidden_channels=256,256 --fp16 --dropout=0.2 --gat_dropout=0.2;

# python train.py --do_train=true --do_eval=true --per_device_train_batch_size=1 --per_device_eval_batch_size=1 --learning_rate=4e-3 --warmup_ratio=0.1 --lr_scheduler_type=cosine --save_strategy=steps --save_steps=2000 --eval_steps=2000 --evaluation_strategy=steps --logging_strategy=steps --logging_steps=200 --save_total_limit=2 --load_best_model_at_end=True --optim=adamw_torch --weight_decay=1e-5 --num_train_epochs=1000 --metric_for_best_model=eval_kendalltau --greater_is_better=True --dataloader_num_workers=4 --max_grad_norm=1.0 --data_type=layout --source=nlp_pruned --search=default --overwrite_output_dir=True --output_dir=./outputs_nlp_default/ --report_to=none --load_best_model_at_end=True --hidden_channels=256,256 --fp16 --dropout=0.2 --gat_dropout=0.2;

# python train.py --do_train=true --do_eval=true --per_device_train_batch_size=1 --per_device_eval_batch_size=1 --learning_rate=4e-3 --warmup_ratio=0.1 --lr_scheduler_type=cosine --save_strategy=steps --save_steps=2000 --eval_steps=2000 --evaluation_strategy=steps --logging_strategy=steps --logging_steps=200 --save_total_limit=2 --load_best_model_at_end=True --optim=adamw_torch --weight_decay=1e-5 --num_train_epochs=1000 --metric_for_best_model=eval_kendalltau --greater_is_better=True --dataloader_num_workers=4 --max_grad_norm=1.0 --data_type=layout --source=nlp_pruned --search=random --overwrite_output_dir=True --output_dir=./outputs_nlp_random/ --report_to=none --load_best_model_at_end=True --hidden_channels=256,256 --fp16 --dropout=0.2 --gat_dropout=0.2;

# python train.py --do_train=true --do_eval=true --per_device_train_batch_size=1 --per_device_eval_batch_size=1 --learning_rate=1e-3 --warmup_ratio=0.1 --lr_scheduler_type=cosine --save_strategy=epoch --evaluation_strategy=epoch --logging_strategy=steps --logging_steps=200 --save_total_limit=2 --load_best_model_at_end=True --optim=adamw_torch --weight_decay=1e-5 --num_train_epochs=20 --metric_for_best_model=eval_score_tile_mean --greater_is_better=True --dataloader_num_workers=4 --max_grad_norm=1.0 --data_type=tile --source=xla --search=default --overwrite_output_dir=True --output_dir=./outputs_tile/ --report_to=none --load_best_model_at_end=True --hidden_channels=32,48,64,84 --graph_in=64 --graph_out=64 --hidden_dim=128 --fp16 --dropout=0.2 --gat_dropout=0.2;



