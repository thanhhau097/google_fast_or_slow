{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kaggle_tpu/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.contrib.concurrent import process_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"/home/edu/code/google_fast_or_slow/data/npz_pad\")\n",
    "collection = \"layout/xla\"\n",
    "ctype = \"random\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_to_int(vec: np.ndarray) -> np.ndarray:\n",
    "    # Powers of 7: [1, 7, 49, 343, 2401, 16807]\n",
    "    powers_of_7 = np.array([7**i for i in range(6)])\n",
    "    return np.dot(vec, powers_of_7).astype(np.int32)\n",
    "\n",
    "\n",
    "def int_to_vec(integers: np.ndarray) -> np.ndarray:\n",
    "    # Create an empty array of shape (N, 6) to store the results\n",
    "    vectors = np.empty((len(integers), 6), dtype=np.int64)\n",
    "\n",
    "    # Divide by powers of 7 and take the remainder to find each digit\n",
    "    for i in range(6):\n",
    "        vectors[:, i] = integers % 7\n",
    "        integers //= 7\n",
    "\n",
    "    return vectors.astype(np.int32)\n",
    "\n",
    "\n",
    "def compress_configs(node_configs):\n",
    "    vecs = node_configs.reshape(-1, 6).astype(np.int32) + 1\n",
    "    ints = vec_to_int(vecs)\n",
    "    ints = ints.reshape(node_configs.shape[0], node_configs.shape[1], 3)\n",
    "    return ints\n",
    "\n",
    "\n",
    "def decompress_configs(node_configs):\n",
    "    ints = node_configs.astype(np.int32).reshape(-1)\n",
    "    vecs = int_to_vec(ints)\n",
    "    vecs = vecs.reshape(node_configs.shape[0], -1, 18) - 1\n",
    "    return vecs\n",
    "    \n",
    "def prune_graph(data):\n",
    "    print(\"Pruning graph...\")\n",
    "    new_data = deepcopy(dict(data))\n",
    "    print(\"Original graph has {} nodes and {} edges\".format(data[\"node_feat\"].shape[0], data[\"edge_index\"].shape[0]))\n",
    "    in_edge_index = data[\"edge_index\"][np.isin(data[\"edge_index\"], data[\"node_config_ids\"]).any(1)]\n",
    "\n",
    "    in_node_ids = np.unique(in_edge_index)\n",
    "    assert len(set(data[\"node_config_ids\"]) - set(in_node_ids)) == 0\n",
    "    lookup = np.ones(data[\"node_feat\"].shape[0]) * -1\n",
    "    lookup[in_node_ids] = np.arange(in_node_ids.shape[0])\n",
    "\n",
    "    in_node_feats = data[\"node_feat\"][in_node_ids, :]\n",
    "    in_node_opcode = data[\"node_opcode\"][in_node_ids]\n",
    "    in_edge_index = lookup[in_edge_index]\n",
    "    in_node_config_ids = lookup[data[\"node_config_ids\"]]\n",
    "\n",
    "    new_data[\"node_feat\"] = in_node_feats\n",
    "    new_data[\"node_opcode\"] = in_node_opcode\n",
    "    new_data[\"edge_index\"] = in_edge_index\n",
    "    new_data[\"node_config_ids\"] = in_node_config_ids\n",
    "    print(\"New graph has {} nodes and {} edges\".format(new_data[\"node_feat\"].shape[0], new_data[\"edge_index\"].shape[0]))\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dupplicated_node_configs(data):\n",
    "    reshaped_config_feat = data[\"node_config_feat\"].reshape(data[\"node_config_feat\"].shape[0], -1) + 2 # avoid zeros\n",
    "    positional_array = np.random.random(reshaped_config_feat.shape[1])  # multiply each value by its position to avoid removing permutations by accident\n",
    "    reshaped_values = (reshaped_config_feat * positional_array[None, :]).sum(1)\n",
    "    is_equal_matrix = reshaped_values[None, :] == reshaped_values[:, None] # quadratic matrix of all pairwise equalities\n",
    "    # is_equal_matrix[np.triu_indices(is_equal_matrix.shape[0], 0)] = 0 # only get diagonal to avoid remove twice\n",
    "    is_equal_matrix = np.tril(is_equal_matrix, -1) # only get diagonal to avoid remove twice\n",
    "    to_remove_ids = np.unique(np.where(is_equal_matrix)[0])\n",
    "    print(\"Removing {} duplicated node configs out of {}\".format(to_remove_ids.shape[0], data[\"node_config_feat\"].shape[0]))\n",
    "    data[\"config_runtime\"] = np.delete(data[\"config_runtime\"], to_remove_ids)\n",
    "    data[\"node_config_feat\"] = np.delete(data[\"node_config_feat\"], to_remove_ids, axis=0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/69 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning graph...\n",
      "Original graph has 13502 nodes and 22209 edges\n",
      "New graph has 2143 nodes and 2137 edges\n",
      "Pruning graph...\n",
      "Original graph has 490 nodes and 729 edges\n",
      "New graph has 65 nodes and 56 edges\n",
      "Removing 39 duplicated node configs out of 1632\n",
      "Pruning graph...\n",
      "Original graph has 4185 nodes and 7209 edges\n",
      "New graph has 224 nodes and 200 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/69 [00:00<00:32,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning graph...\n",
      "Original graph has 6328 nodes and 12014 edges\n",
      "New graph has 426 nodes and 375 edges\n",
      "Removing 459 duplicated node configs out of 100040\n",
      "Pruning graph...\n",
      "Original graph has 13342 nodes and 21709 edges\n",
      "New graph has 1820 nodes and 1622 edges\n",
      "Removing 39 duplicated node configs out of 1152\n",
      "Pruning graph...\n",
      "Original graph has 5809 nodes and 10345 edges\n",
      "New graph has 594 nodes and 599 edges\n",
      "Removing 39 duplicated node configs out of 7208\n",
      "Pruning graph...\n",
      "Original graph has 15642 nodes and 25387 edges\n",
      "New graph has 3878 nodes and 3394 edges\n",
      "Removing 19 duplicated node configs out of 20\n",
      "Pruning graph...\n",
      "Original graph has 8847 nodes and 14797 edges\n",
      "New graph has 811 nodes and 806 edges\n",
      "Removing 39 duplicated node configs out of 7440\n",
      "Pruning graph...\n",
      "Original graph has 17472 nodes and 27130 edges\n",
      "New graph has 4211 nodes and 4097 edges\n",
      "Removing 39 duplicated node configs out of 156\n",
      "Pruning graph...\n",
      "Original graph has 40332 nodes and 71912 edges\n",
      "New graph has 7304 nodes and 6804 edges\n",
      "Removing 39 duplicated node configs out of 10760\n",
      "Removing 99992 duplicated node configs out of 100040\n",
      "Pruning graph...\n",
      "Pruning graph...\n",
      "Original graph has 5162 nodes and 9160 edges\n",
      "New graph has 535 nodes and 550 edges\n",
      "Original graph has 15809 nodes and 25564 edges\n",
      "New graph has 3884 nodes and 3400 edges\n",
      "Removing 40 duplicated node configs out of 11336\n",
      "Removing 47 duplicated node configs out of 9744\n",
      "Pruning graph...\n",
      "Original graph has 6136 nodes and 10670 edges\n",
      "New graph has 488 nodes and 493 edges\n",
      "Removing 98744 duplicated node configs out of 100040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/69 [00:30<20:10, 18.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 40 duplicated node configs out of 9552\n",
      "Pruning graph...\n",
      "Original graph has 19662 nodes and 35460 edges\n",
      "New graph has 2085 nodes and 2100 edges\n",
      "Pruning graph...\n",
      "Original graph has 13867 nodes and 22162 edges\n",
      "New graph has 995 nodes and 1045 edges\n",
      "Removing 39 duplicated node configs out of 1155\n",
      "Removing 39 duplicated node configs out of 5502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 11/69 [00:31<02:06,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 14/69 [00:32<01:26,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning graph...\n",
      "Original graph has 24790 nodes and 32709 edges\n",
      "New graph has 6411 nodes and 4774 edges\n",
      "Original graph has 7324 nodes and 12087 edges\n",
      "New graph has 1067 nodes and 1230 edges\n",
      "Removing 39 duplicated node configs out of 3718\n",
      "Pruning graph...\n",
      "Removing 39 duplicated node configs out of 22632\n",
      "Original graph has 21196 nodes and 37779 edges\n",
      "New graph has 3848 nodes and 3395 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 16/69 [00:33<01:15,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning graph...\n",
      "Original graph has 5345 nodes and 8775 edges\n",
      "New graph has 599 nodes and 601 edges\n",
      "Removing 42 duplicated node configs out of 10664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 17/69 [00:34<01:09,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning graph...\n",
      "Original graph has 1111 nodes and 1557 edges\n",
      "New graph has 215 nodes and 164 edges\n",
      "Pruning graph...\n",
      "Original graph has 8836 nodes and 15567 edges\n",
      "New graph has 768 nodes and 782 edges\n",
      "Removing 39 duplicated node configs out of 5744\n",
      "Pruning graph...\n",
      "Original graph has 5605 nodes and 9018 edges\n",
      "New graph has 476 nodes and 483 edges\n",
      "Removing 41 duplicated node configs out of 9536\n",
      "Pruning graph...\n",
      "Original graph has 5162 nodes and 9160 edges\n",
      "New graph has 535 nodes and 550 edges\n",
      "Removing 39 duplicated node configs out of 17592Removing 39 duplicated node configs out of 8368\n",
      "\n",
      "Pruning graph...\n",
      "Original graph has 650 nodes and 1100 edges\n",
      "New graph has 180 nodes and 139 edges\n",
      "Removing 26983 duplicated node configs out of 31584\n",
      "Pruning graph...\n",
      "Original graph has 5605 nodes and 9018 edges\n",
      "New graph has 476 nodes and 483 edges\n",
      "Removing 39 duplicated node configs out of 7560\n",
      "Pruning graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 18/69 [00:39<01:39,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original graph has 21338 nodes and 37243 edges\n",
      "Pruning graph...\n",
      "New graph has 3538 nodes and 3283 edges\n",
      "Original graph has 4748 nodes and 8547 edges\n",
      "New graph has 766 nodes and 834 edges\n",
      "Removing 39 duplicated node configs out of 15112\n",
      "Pruning graph...\n",
      "Original graph has 17135 nodes and 26568 edges\n",
      "New graph has 4211 nodes and 4097 edges\n",
      "Removing 39 duplicated node configs out of 148\n",
      "Pruning graph...\n",
      "Original graph has 15022 nodes and 27044 edges\n",
      "New graph has 1589 nodes and 1604 edges\n",
      "Removing 39 duplicated node configs out of 18776\n",
      "Removing 39 duplicated node configs out of 6792\n",
      "Pruning graph...\n",
      "Original graph has 20665 nodes and 36659 edges\n",
      "New graph has 3633 nodes and 3380 edges\n",
      "Pruning graph...\n",
      "Removing 39 duplicated node configs out of 22944\n",
      "Original graph has 12062 nodes and 21268 edges\n",
      "New graph has 2424 nodes and 2518 edges\n",
      "Pruning graph...\n",
      "Original graph has 19348 nodes and 30351 edges\n",
      "New graph has 1756 nodes and 1767 edges\n",
      "Removing 39 duplicated node configs out of 2374\n",
      "Pruning graph...\n",
      "Original graph has 6656 nodes and 10799 edges\n",
      "New graph has 623 nodes and 612 edges\n",
      "Removing 39 duplicated node configs out of 3736\n",
      "Pruning graph...\n",
      "Original graph has 12565 nodes and 20569 edges\n",
      "New graph has 1660 nodes and 1508 edges\n",
      "Removing 39 duplicated node configs out of 1140\n",
      "Removing 18373 duplicated node configs out of 36920\n",
      "Removing 58910 duplicated node configs out of 100040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 24/69 [00:56<01:48,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning graph...\n",
      "Original graph has 1111 nodes and 1557 edges\n",
      "New graph has 215 nodes and 164 edges\n",
      "Pruning graph...\n",
      "Original graph has 24793 nodes and 32713 edges\n",
      "New graph has 6417 nodes and 4779 edges\n",
      "Removing 457 duplicated node configs out of 21736\n",
      "Pruning graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 31/69 [00:58<00:51,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning graph...\n",
      "Original graph has 22385 nodes and 39976 edges\n",
      "New graph has 4023 nodes and 3532 edges\n",
      "Original graph has 10092 nodes and 18102 edges\n",
      "New graph has 1062 nodes and 1077 edges\n",
      "Removing 39 duplicated node configs out of 11240\n",
      "Removing 39 duplicated node configs out of 7040\n",
      "Pruning graph...\n",
      "Original graph has 1277 nodes and 2063 edges\n",
      "New graph has 189 nodes and 172 edges\n",
      "Removing 19 duplicated node configs out of 20\n",
      "Pruning graph...\n",
      "Original graph has 43615 nodes and 73881 edges\n",
      "New graph has 3142 nodes and 3089 edges\n",
      "Removing 39 duplicated node configs out of 1871\n",
      "Removing 39 duplicated node configs out of 17088\n",
      "Pruning graph...\n",
      "Original graph has 14680 nodes and 23604 edges\n",
      "New graph has 2964 nodes and 2521 edges\n",
      "Pruning graph...\n",
      "Original graph has 1383 nodes and 2167 edges\n",
      "New graph has 209 nodes and 188 edges\n",
      "Removing 19 duplicated node configs out of 20\n",
      "Pruning graph...\n",
      "Original graph has 16818 nodes and 26250 edges\n",
      "New graph has 4099 nodes and 4017 edges\n",
      "Removing 19 duplicated node configs out of 20\n",
      "Pruning graph...\n",
      "Original graph has 5673 nodes and 9099 edges\n",
      "New graph has 493 nodes and 495 edges\n",
      "Removing 39 duplicated node configs out of 12320\n",
      "Removing 40 duplicated node configs out of 10224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 35/69 [01:02<00:43,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning graph...\n",
      "Original graph has 15022 nodes and 27044 edges\n",
      "New graph has 1589 nodes and 1604 edges\n",
      "Pruning graph...\n",
      "Removing 39 duplicated node configs out of 6080\n",
      "Original graph has 8636 nodes and 14661 edges\n",
      "New graph has 1188 nodes and 1086 edges\n",
      "Pruning graph...\n",
      "Original graph has 10449 nodes and 16824 edges\n",
      "New graph has 1024 nodes and 1084 edges\n",
      "Removing 39 duplicated node configs out of 2118\n",
      "Pruning graph...\n",
      "Original graph has 9257 nodes and 15281 edges\n",
      "New graph has 1188 nodes and 1086 edges\n",
      "Removing 39 duplicated node configs out of 11880\n",
      "Removing 39 duplicated node configs out of 11296\n",
      "Pruning graph...\n",
      "Original graph has 2774 nodes and 4730 edges\n",
      "New graph has 168 nodes and 168 edges\n",
      "Removing 39 duplicated node configs out of 380\n",
      "Pruning graph...\n",
      "Pruning graph...\n",
      "Original graph has 5689 nodes and 9131 edges\n",
      "New graph has 476 nodes and 483 edges\n",
      "Original graph has 15748 nodes and 23128 edges\n",
      "New graph has 3829 nodes and 3095 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 41/69 [01:04<00:25,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning graph...\n",
      "Original graph has 5670 nodes and 10166 edges\n",
      "New graph has 933 nodes and 1030 edges\n",
      "Removing 39 duplicated node configs out of 2239\n",
      "Removing 39 duplicated node configs out of 2887\n",
      "Removing 39 duplicated node configs out of 7464\n",
      "Pruning graph...\n",
      "Original graph has 15809 nodes and 25564 edges\n",
      "New graph has 3884 nodes and 3400 edges\n",
      "Removing 19 duplicated node configs out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 49/69 [01:04<00:11,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning graph...\n",
      "Original graph has 12069 nodes and 21320 edges\n",
      "New graph has 1059 nodes and 1084 edges\n",
      "Removing 54 duplicated node configs out of 7088\n",
      "Pruning graph...\n",
      "Pruning graph...\n",
      "Original graph has 7324 nodes and 12087 edges\n",
      "New graph has 1067 nodes and 1230 edges\n",
      "Original graph has 39452 nodes and 70171 edges\n",
      "New graph has 6990 nodes and 6516 edges\n",
      "Pruning graph...\n",
      "Original graph has 5673 nodes and 9099 edges\n",
      "New graph has 493 nodes and 495 edges\n",
      "Removing 39 duplicated node configs out of 7384\n",
      "Pruning graph...\n",
      "Original graph has 13867 nodes and 22162 edges\n",
      "New graph has 995 nodes and 1045 edges\n",
      "Removing 39 duplicated node configs out of 1489\n",
      "Removing 39 duplicated node configs out of 9760\n",
      "Removing 39 duplicated node configs out of 22992\n",
      "Pruning graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 54/69 [01:08<00:09,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning graph...\n",
      "Original graph has 5279 nodes and 8694 edges\n",
      "New graph has 582 nodes and 589 edges\n",
      "Removing 39 duplicated node configs out of 9600\n",
      "Original graph has 25544 nodes and 33522 edges\n",
      "New graph has 9294 nodes and 6926 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 55/69 [01:09<00:09,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning graph...\n",
      "Original graph has 372 nodes and 597 edges\n",
      "New graph has 73 nodes and 73 edges\n",
      "Pruning graph...\n",
      "Original graph has 21126 nodes and 37368 edges\n",
      "New graph has 3698 nodes and 3437 edges\n",
      "Removing 39 duplicated node configs out of 10480\n",
      "Removing 39 duplicated node configs out of 18368\n",
      "Removing 191 duplicated node configs out of 29144\n",
      "Pruning graph...\n",
      "Original graph has 7768 nodes and 13121 edges\n",
      "New graph has 630 nodes and 633 edges\n",
      "Removing 39 duplicated node configs out of 8376\n",
      "Pruning graph...\n",
      "Original graph has 5358 nodes and 9631 edges\n",
      "New graph has 933 nodes and 1030 edges\n",
      "Removing 39 duplicated node configs out of 2994\n",
      "Pruning graph...\n",
      "Original graph has 21335 nodes and 37236 edges\n",
      "New graph has 3538 nodes and 3283 edges\n",
      "Pruning graph...\n",
      "Original graph has 26234 nodes and 48094 edges\n",
      "New graph has 5529 nodes and 5136 edges\n",
      "Removing 39 duplicated node configs out of 15704\n",
      "Removing 39 duplicated node configs out of 19128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 59/69 [01:17<00:10,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning graph...\n",
      "Original graph has 26906 nodes and 48823 edges\n",
      "New graph has 5461 nodes and 5066 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 65/69 [01:20<00:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning graph...\n",
      "Original graph has 19662 nodes and 35460 edges\n",
      "New graph has 2085 nodes and 2100 edges\n",
      "Removing 40 duplicated node configs out of 6015\n",
      "Pruning graph...\n",
      "Original graph has 8836 nodes and 15567 edges\n",
      "New graph has 768 nodes and 782 edges\n",
      "Removing 51 duplicated node configs out of 7584\n",
      "Removing 39 duplicated node configs out of 12720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:23<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading valid data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning graph...\n",
      "Original graph has 3163 nodes and 5112 edges\n",
      "New graph has 223 nodes and 181 edges\n",
      "Pruning graph...\n",
      "Pruning graph...\n",
      "Original graph has 5673 nodes and 9099 edges\n",
      "New graph has 493 nodes and 495 edges\n",
      "Original graph has 12067 nodes and 21319 edges\n",
      "New graph has 1059 nodes and 1084 edges\n",
      "Pruning graph...\n",
      "Original graph has 6135 nodes and 10670 edges\n",
      "New graph has 488 nodes and 493 edges\n",
      "Pruning graph...\n",
      "Original graph has 19541 nodes and 30520 edges\n",
      "New graph has 4807 nodes and 4498 edges\n",
      "Pruning graph...\n",
      "Original graph has 21335 nodes and 37236 edges\n",
      "New graph has 3538 nodes and 3283 edges\n",
      "Pruning graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2/7 [00:01<00:04,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original graph has 21664 nodes and 38485 edges\n",
      "New graph has 3889 nodes and 3480 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:04<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning graph...\n",
      "Pruning graph...\n",
      "Original graph has 5279 nodes and 8694 edges\n",
      "Original graph has 5810 nodes and 10345 edges\n",
      "New graph has 582 nodes and 589 edges\n",
      "New graph has 594 nodes and 599 edges\n",
      "Pruning graph...\n",
      "Original graph has 490 nodes and 749 edges\n",
      "New graph has 118 nodes and 116 edges\n",
      "Pruning graph...\n",
      "Original graph has 43615 nodes and 73881 edges\n",
      "New graph has 3142 nodes and 3089 edges\n",
      "Pruning graph...\n",
      "Pruning graph...\n",
      "Original graph has 23363 nodes and 38984 edges\n",
      "New graph has 6140 nodes and 6482 edges\n",
      "Original graph has 24790 nodes and 32709 edges\n",
      "New graph has 6411 nodes and 4774 edges\n",
      "Pruning graph...\n",
      "Original graph has 41522 nodes and 72902 edges\n",
      "New graph has 6959 nodes and 6466 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [00:00<00:01,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning graph...\n",
      "Original graph has 43615 nodes and 73881 edges\n",
      "New graph has 3142 nodes and 3089 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.33it/s]\n"
     ]
    }
   ],
   "source": [
    "dst_dir = root / f\"{collection}_pruned\" / ctype\n",
    "\n",
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    print(\"Loading {} data...\".format(split))\n",
    "    split_src_dir = root / collection / ctype / split\n",
    "    split_dst_dir = dst_dir / split\n",
    "    split_dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def _process_one_npz(npz_path):\n",
    "        data = dict(np.load(str(npz_path), allow_pickle=True))\n",
    "        data = prune_graph(data)\n",
    "        if split == \"train\":\n",
    "            data = remove_dupplicated_node_configs(data)\n",
    "        data[\"node_config_feat\"] = compress_configs(data[\"node_config_feat\"])\n",
    "        np.savez_compressed(split_dst_dir / npz_path.name, **data)\n",
    "    \n",
    "    process_map(_process_one_npz, list(split_src_dir.glob(\"*.npz\")), max_workers=3)\n",
    "\n",
    "    # for npz_path in tqdm(list(split_src_dir.glob(\"*.npz\"))):\n",
    "        # print(npz_path)\n",
    "        # data = dict(np.load(str(npz_path), allow_pickle=True))\n",
    "        # data = prune_graph(data)\n",
    "        # if split == \"train\":\n",
    "        #     data = remove_dupplicated_node_configs(data)\n",
    "        # data[\"node_config_feat\"] = compress_configs(data[\"node_config_feat\"])\n",
    "        # np.savez_compressed(split_dst_dir / npz_path.name, **data)\n",
    "        # if split == \"valid\":\n",
    "        #     data = remove_dupplicated_node_configs(data)\n",
    "        #     dedup_dst_dir = Path(str(split_dst_dir).replace(\"valid\", \"valid_dedup\"))\n",
    "        #     dedup_dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "        #     np.savez(dedup_dst_dir / npz_path.name, **data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "root = Path(\"/home/edu/code/google_fast_or_slow/data/npz_all/npz\")\n",
    "collection = \"layout/xla_pruned\"\n",
    "ctype = \"default\"\n",
    "\n",
    "split_src_dir = root / collection / ctype / \"train\"\n",
    "df = []\n",
    "for path in tqdm(list(split_src_dir.glob(\"*.npz\"))):\n",
    "    data = dict(np.load(str(path), allow_pickle=True))\n",
    "    times = data['config_runtime']\n",
    "    if len(times) < 2:\n",
    "        continue\n",
    "    times = np.sort(times)\n",
    "    deltas = times[1:] - times[:-1]\n",
    "    stats = {\"file\": path.stem, \"median\": np.median(deltas), \"mean\": np.mean(deltas), \"std\": np.std(deltas), \"min\": np.min(deltas), \"max\": np.max(deltas), \"p10\": np.percentile(deltas, 10), \"p90\": np.percentile(deltas, 90)}\n",
    "    df.append(stats)\n",
    "    # ids = np.where(data[\"node_opcode\"][data[\"node_config_ids\"].astype(int)] == 75)\n",
    "    # if ids:\n",
    "    #     ids = ids[0]\n",
    "    #     data[\"node_config_feat\"] = decompress_configs(data[\"node_config_feat\"])\n",
    "    #     counter.extend(data[\"node_config_feat\"][:, ids][:, :, [2, 3, 4, 5, 8, 9, 10, 11, 14, 15, 16, 17]].reshape(-1))\n",
    "df_default = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random.iloc[:, 1:].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_default.iloc[:, 1:].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats # random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats # default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(counter, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(np.load(\"/home/edu/code/google_fast_or_slow/data/npz_pad/layout/xla/random/train/resnet_v2_50_batch_16.npz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"node_config_feat\"] = decompress_configs(data[\"node_config_feat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = []\n",
    "for i in data[\"node_config_feat\"][:, 0, :]:\n",
    "    seqs.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(seqs, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"node_opcode\"][497]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(enumerate(data[\"node_feat\"][497, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(enumerate(data[\"node_feat\"][497, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"node_config_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"node_opcode\"][data[\"node_config_ids\"][0:450].astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(data[\"node_opcode\"][data[\"node_config_ids\"].astype(int)], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"node_config_feat\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_node(idx):\n",
    "    print(\"Node idx: {}\".format(idx))\n",
    "    print(\"Node opcode: {}\".format(data[\"node_opcode\"][idx]))\n",
    "    print(\"Node config id: {}\".format(data[\"node_config_ids\"][idx]))\n",
    "    print(\"Node config feat: {}\".format(data[\"node_config_feat\"][idx]))\n",
    "    print(\"Node feat: {}\".format(data[\"node_feat\"][idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.load(\"/home/edu/code/google_fast_or_slow/outputs_xla_default/checkpoint-12000/pytorch_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['embedding_op.weight', 'embedding_layout_cfg.weight', 'linear.linear.weight', 'linear.linear.bias', 'linear.cross_attn.temperature', 'linear.attn.linear1.weight', 'linear.attn.linear1.bias', 'linear.attn.linear2.weight', 'linear.attn.linear2.bias', 'convs.0.conv.lin_l.weight', 'convs.0.conv.lin_l.bias', 'convs.0.conv.lin_r.weight', 'convs.0.attn.linear1.weight', 'convs.0.attn.linear1.bias', 'convs.0.attn.linear2.weight', 'convs.0.attn.linear2.bias', 'convs.0.cross_attn.temperature', 'convs.1.conv.lin_l.weight', 'convs.1.conv.lin_l.bias', 'convs.1.conv.lin_r.weight', 'convs.1.attn.linear1.weight', 'convs.1.attn.linear1.bias', 'convs.1.attn.linear2.weight', 'convs.1.attn.linear2.bias', 'convs.1.cross_attn.temperature', 'classifier.weight', 'classifier.bias'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('linear.cross_attn.temperature', tensor(0.6401, device='cuda:0')),\n",
       " ('convs.0.cross_attn.temperature', tensor(0.3068, device='cuda:0')),\n",
       " ('convs.1.cross_attn.temperature', tensor(0.3477, device='cuda:0'))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(_, x[_]) for _ in x.keys() if \"cross_attn.temperature\" in _]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.randint(1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"/home/edu/code/google_fast_or_slow/data/npz_pad/layout/xla_pruned_compressed/default/test/3e7156ac468dfb75cf5c9615e1e5887d.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"config_runtime\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"/home/edu/code/google_fast_or_slow/outputs_xla_random/fold_0/scaler.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    \"/home/edu/code/google_fast_or_slow/outputs_probs/layout:xla_pruned:random:val_probs_cross_128_701.csv\",\n",
    "    \"/home/edu/code/google_fast_or_slow/outputs_probs/layout:xla_pruned:random:val_probs_no_cross_685.csv\",\n",
    "]\n",
    "weights = [0.5, 0.5]\n",
    "root = Path(\"/home/edu/code/google_fast_or_slow/data/npz_pad/layout/\")\n",
    "collection = \"xla_pruned_compressed\"\n",
    "search = \"random\"\n",
    "split = \"valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_probs = []\n",
    "for p, w in zip(paths, weights):\n",
    "    df = pd.read_csv(p)\n",
    "    filenames = df[\"ID\"].tolist()\n",
    "    gts = df[\"gts\"].apply(lambda x: list(map(float, x.split(\";\")))).tolist()\n",
    "    probs = df[\"probs\"].apply(lambda x: list(map(float, x.split(\";\")))).tolist()\n",
    "    probs = [np.array(_) * w for _ in probs]\n",
    "    all_probs.append(probs)\n",
    "\n",
    "avg_probs = []\n",
    "for i in range(len(filenames)):\n",
    "    avg_probs.append(np.stack([model_prob[i] for model_prob in all_probs]).sum(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9787235221144981,\n",
       " 0.6396126601435936,\n",
       " 0.49751865369094184,\n",
       " 0.9267971867094805,\n",
       " 0.7788089689258385,\n",
       " 0.7192630813017497,\n",
       " 0.35548091897764134]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import kendalltau\n",
    "score = [kendalltau(p, gt).statistic for p, gt in zip(avg_probs, gts)]\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6994578559805349"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 39 duplicated node configs out of 19040\n",
      "Removing 39 duplicated node configs out of 4688\n",
      "Removing 39 duplicated node configs out of 5288\n",
      "Removing 39 duplicated node configs out of 5704\n",
      "Removing 39 duplicated node configs out of 7248\n",
      "Removing 39 duplicated node configs out of 17360\n",
      "Removing 39 duplicated node configs out of 481\n"
     ]
    }
   ],
   "source": [
    "# create pseudo labels\n",
    "src_dir = root / collection / search / split\n",
    "dst_dir = root / collection / search / f\"{split}_pseudo\"\n",
    "dst_dir.mkdir(exist_ok=True)\n",
    "for file, pseudo_runtime in zip(filenames, avg_probs):\n",
    "    file = file.split(\":\")[-1] + \".npz\"\n",
    "    data = dict(np.load(str(src_dir / file), allow_pickle=True))\n",
    "    assert len(data[\"config_runtime\"]) == len(pseudo_runtime)\n",
    "    data[\"config_runtime\"] = pseudo_runtime\n",
    "    data = remove_dupplicated_node_configs(data)\n",
    "    np.savez_compressed(str(dst_dir / file), **data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediction_indices = []\n",
    "for pred_prob in avg_probs:\n",
    "    prediction = np.argsort(pred_prob)\n",
    "    prediction_indices.append(\";\".join([str(int(e)) for e in prediction]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "submission_df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"ID\": filenames,\n",
    "        \"TopConfigs\": prediction_indices,\n",
    "    }\n",
    ")\n",
    "\n",
    "submission_df.to_csv(\n",
    "    os.path.join(\n",
    "        \"/home/edu/code/google_fast_or_slow/outputs_csv\",\n",
    "        f\"layout:xla:{search}:submission.csv\",\n",
    "    ),\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_tpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
