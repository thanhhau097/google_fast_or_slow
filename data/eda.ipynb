{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.contrib.concurrent import process_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"/home/edu/code/google_fast_or_slow/data/npz_all/npz\")\n",
    "collection = \"layout/nlp\"\n",
    "ctype = \"random\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_to_int(vec: np.ndarray) -> np.ndarray:\n",
    "    # Powers of 7: [1, 7, 49, 343, 2401, 16807]\n",
    "    powers_of_7 = np.array([7**i for i in range(6)])\n",
    "    return np.dot(vec, powers_of_7).astype(np.int32)\n",
    "\n",
    "\n",
    "def int_to_vec(integers: np.ndarray) -> np.ndarray:\n",
    "    # Create an empty array of shape (N, 6) to store the results\n",
    "    vectors = np.empty((len(integers), 6), dtype=np.int64)\n",
    "\n",
    "    # Divide by powers of 7 and take the remainder to find each digit\n",
    "    for i in range(6):\n",
    "        vectors[:, i] = integers % 7\n",
    "        integers //= 7\n",
    "\n",
    "    return vectors.astype(np.int32)\n",
    "\n",
    "\n",
    "def compress_configs(node_configs):\n",
    "    vecs = node_configs.reshape(-1, 6).astype(np.int32) + 1\n",
    "    ints = vec_to_int(vecs)\n",
    "    ints = ints.reshape(node_configs.shape[0], node_configs.shape[1], 3)\n",
    "    return ints\n",
    "\n",
    "\n",
    "def decompress_configs(node_configs):\n",
    "    ints = node_configs.astype(np.int32).reshape(-1)\n",
    "    vecs = int_to_vec(ints)\n",
    "    vecs = vecs.reshape(node_configs.shape[0], -1, 18) - 1\n",
    "    return vecs\n",
    "    \n",
    "def prune_graph(data):\n",
    "    print(\"Pruning graph...\")\n",
    "    new_data = deepcopy(dict(data))\n",
    "    print(\"Original graph has {} nodes and {} edges\".format(data[\"node_feat\"].shape[0], data[\"edge_index\"].shape[0]))\n",
    "    in_edge_index = data[\"edge_index\"][np.isin(data[\"edge_index\"], data[\"node_config_ids\"]).any(1)]\n",
    "\n",
    "    in_node_ids = np.unique(in_edge_index)\n",
    "    assert len(set(data[\"node_config_ids\"]) - set(in_node_ids)) == 0\n",
    "    lookup = np.ones(data[\"node_feat\"].shape[0]) * -1\n",
    "    lookup[in_node_ids] = np.arange(in_node_ids.shape[0])\n",
    "\n",
    "    in_node_feats = data[\"node_feat\"][in_node_ids, :]\n",
    "    in_node_opcode = data[\"node_opcode\"][in_node_ids]\n",
    "    in_edge_index = lookup[in_edge_index]\n",
    "    in_node_config_ids = lookup[data[\"node_config_ids\"]]\n",
    "\n",
    "    new_data[\"node_feat\"] = in_node_feats\n",
    "    new_data[\"node_opcode\"] = in_node_opcode\n",
    "    new_data[\"edge_index\"] = in_edge_index\n",
    "    new_data[\"node_config_ids\"] = in_node_config_ids\n",
    "    print(\"New graph has {} nodes and {} edges\".format(new_data[\"node_feat\"].shape[0], new_data[\"edge_index\"].shape[0]))\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dupplicated_node_configs(data):\n",
    "    reshaped_config_feat = data[\"node_config_feat\"].reshape(data[\"node_config_feat\"].shape[0], -1) + 2 # avoid zeros\n",
    "    positional_array = np.random.random(reshaped_config_feat.shape[1])  # multiply each value by its position to avoid removing permutations by accident\n",
    "    reshaped_values = (reshaped_config_feat * positional_array[None, :]).sum(1)\n",
    "    is_equal_matrix = reshaped_values[None, :] == reshaped_values[:, None] # quadratic matrix of all pairwise equalities\n",
    "    # is_equal_matrix[np.triu_indices(is_equal_matrix.shape[0], 0)] = 0 # only get diagonal to avoid remove twice\n",
    "    is_equal_matrix = np.tril(is_equal_matrix, -1) # only get diagonal to avoid remove twice\n",
    "    to_remove_ids = np.unique(np.where(is_equal_matrix)[0])\n",
    "    print(\"Removing {} duplicated node configs out of {}\".format(to_remove_ids.shape[0], data[\"node_config_feat\"].shape[0]))\n",
    "    data[\"config_runtime\"] = np.delete(data[\"config_runtime\"], to_remove_ids)\n",
    "    data[\"node_config_feat\"] = np.delete(data[\"node_config_feat\"], to_remove_ids, axis=0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_dir = root / f\"{collection}_pruned\" / ctype\n",
    "\n",
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    print(\"Loading {} data...\".format(split))\n",
    "    split_src_dir = root / collection / ctype / split\n",
    "    split_dst_dir = dst_dir / split\n",
    "    split_dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def _process_one_npz(npz_path):\n",
    "        data = dict(np.load(str(npz_path), allow_pickle=True))\n",
    "        data = prune_graph(data)\n",
    "        if split == \"train\":\n",
    "            data = remove_dupplicated_node_configs(data)\n",
    "        data[\"node_config_feat\"] = compress_configs(data[\"node_config_feat\"])\n",
    "        np.savez_compressed(split_dst_dir / npz_path.name, **data)\n",
    "    \n",
    "    process_map(_process_one_npz, list(split_src_dir.glob(\"*.npz\")), max_workers=3)\n",
    "\n",
    "    # for npz_path in tqdm(list(split_src_dir.glob(\"*.npz\"))):\n",
    "        # print(npz_path)\n",
    "        # data = dict(np.load(str(npz_path), allow_pickle=True))\n",
    "        # data = prune_graph(data)\n",
    "        # if split == \"train\":\n",
    "        #     data = remove_dupplicated_node_configs(data)\n",
    "        # data[\"node_config_feat\"] = compress_configs(data[\"node_config_feat\"])\n",
    "        # np.savez_compressed(split_dst_dir / npz_path.name, **data)\n",
    "        # if split == \"valid\":\n",
    "        #     data = remove_dupplicated_node_configs(data)\n",
    "        #     dedup_dst_dir = Path(str(split_dst_dir).replace(\"valid\", \"valid_dedup\"))\n",
    "        #     dedup_dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "        #     np.savez(dedup_dst_dir / npz_path.name, **data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_tpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
