{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "\n",
    "def get_obj_mbs(obj, cp=True):\n",
    "    return sys.getsizeof(copy.deepcopy(obj) if cp else obj) / (1<<20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"./npz_all/npz\")\n",
    "# collection = \"layout/xla\"\n",
    "collection = \"layout/nlp\"\n",
    "ctype = \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_graph(data):\n",
    "    # print(\"Pruning graph...\")\n",
    "    new_data = deepcopy(dict(data))\n",
    "    # print(\"Original graph has {} nodes and {} edges\".format(data[\"node_feat\"].shape[0], data[\"edge_index\"].shape[0]))\n",
    "    in_edge_index = data[\"edge_index\"][np.isin(data[\"edge_index\"], data[\"node_config_ids\"]).any(1)]\n",
    "\n",
    "    in_node_ids = np.unique(in_edge_index)\n",
    "    assert len(set(data[\"node_config_ids\"]) - set(in_node_ids)) == 0\n",
    "    lookup = np.ones(data[\"node_feat\"].shape[0]) * -1\n",
    "    lookup[in_node_ids] = np.arange(in_node_ids.shape[0])\n",
    "\n",
    "    in_node_feats = data[\"node_feat\"][in_node_ids, :]\n",
    "    in_node_opcode = data[\"node_opcode\"][in_node_ids]\n",
    "    in_edge_index = lookup[in_edge_index]\n",
    "    in_node_config_ids = lookup[data[\"node_config_ids\"]]\n",
    "\n",
    "    new_data[\"node_feat\"] = in_node_feats\n",
    "    new_data[\"node_opcode\"] = in_node_opcode\n",
    "    new_data[\"edge_index\"] = in_edge_index\n",
    "    new_data[\"node_config_ids\"] = in_node_config_ids\n",
    "    # print(\"New graph has {} nodes and {} edges\".format(new_data[\"node_feat\"].shape[0], new_data[\"edge_index\"].shape[0]))\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dupplicated_node_configs(data):\n",
    "    reshaped_config_feat = data[\"node_config_feat\"].reshape(data[\"node_config_feat\"].shape[0], -1) + 2 # avoid zeros\n",
    "    positional_array = np.random.random(reshaped_config_feat.shape[1])  # multiply each value by its position to avoid removing permutations by accident\n",
    "    reshaped_values = (reshaped_config_feat * positional_array[None, :]).sum(1)\n",
    "    is_equal_matrix = reshaped_values[None, :] == reshaped_values[:, None] # quadratic matrix of all pairwise equalities\n",
    "    # is_equal_matrix[np.triu_indices(is_equal_matrix.shape[0], 0)] = 0 # only get diagonal to avoid remove twice\n",
    "    is_equal_matrix = np.tril(is_equal_matrix, -1) # only get diagonal to avoid remove twice\n",
    "    to_remove_ids = np.unique(np.where(is_equal_matrix)[0])\n",
    "    # print(\"Removing {} duplicated node configs out of {}\".format(to_remove_ids.shape[0], data[\"node_config_feat\"].shape[0]))\n",
    "    data[\"config_runtime\"] = np.delete(data[\"config_runtime\"], to_remove_ids)\n",
    "    data[\"node_config_feat\"] = np.delete(data[\"node_config_feat\"], to_remove_ids, axis=0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicate_rows(data):\n",
    "    matrix = data[\"node_config_feat\"].reshape(data[\"node_config_feat\"].shape[0], -1).astype(np.int32)\n",
    "\n",
    "    # Get unique rows and inverse index\n",
    "    _, unique_idx, inverse = np.unique(matrix, axis=0, return_index=True, return_inverse=True)\n",
    "    \n",
    "    # Create a dictionary of duplicates\n",
    "    duplicates = {}\n",
    "    for i, inv in enumerate(inverse):\n",
    "        if list(np.where(inverse == inv)[0]) != [i]:\n",
    "            duplicates.setdefault(unique_idx[inv], []).append(i)\n",
    "    \n",
    "    # Filter out entries with only one index (i.e., unique rows)\n",
    "    dup_config_dct = {k: np.array(v) for k, v in duplicates.items() if len(v) > 1}\n",
    "\n",
    "    all_dup_idx = [v[v != k] for k, v in dup_config_dct.items()]\n",
    "    all_dup_idx = np.concatenate(all_dup_idx) if len(all_dup_idx) else []\n",
    "\n",
    "    return dup_config_dct, all_dup_idx\n",
    "\n",
    "\n",
    "def dedup_configs(data):\n",
    "    dup_config_dct, all_dup_idx = find_duplicate_rows(data)\n",
    "\n",
    "    for org_idx, idx_list in dup_config_dct.items():\n",
    "        data[\"config_runtime\"][org_idx] = round(np.mean(data[\"config_runtime\"][idx_list]))\n",
    "\n",
    "    if len(all_dup_idx):\n",
    "        data[\"config_runtime\"] = np.delete(data[\"config_runtime\"], all_dup_idx)\n",
    "        data[\"node_config_feat\"] = np.delete(data[\"node_config_feat\"], all_dup_idx, axis=0)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def test_dedup_configs(data):\n",
    "    res = remove_dupplicated_node_configs(copy.deepcopy(data))[\"node_config_feat\"].shape == dedup_configs(copy.deepcopy(data))[\"node_config_feat\"].shape\n",
    "    assert res\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_to_int(vec: np.ndarray) -> np.ndarray:\n",
    "    # Powers of 7: [1, 7, 49, 343, 2401, 16807]\n",
    "    powers_of_7 = np.array([7**i for i in range(6)])\n",
    "    return np.dot(vec, powers_of_7).astype(np.int32)\n",
    "\n",
    "\n",
    "def int_to_vec(integers: np.ndarray) -> np.ndarray:\n",
    "    # Create an empty array of shape (N, 6) to store the results\n",
    "    vectors = np.empty((len(integers), 6), dtype=np.int64)\n",
    "\n",
    "    # Divide by powers of 7 and take the remainder to find each digit\n",
    "    for i in range(6):\n",
    "        vectors[:, i] = integers % 7\n",
    "        integers //= 7\n",
    "\n",
    "    return vectors.astype(np.int32)\n",
    "\n",
    "\n",
    "def compress_configs(node_configs):\n",
    "    vecs = node_configs.reshape(-1, 6).astype(np.int32) + 1\n",
    "    ints = vec_to_int(vecs)\n",
    "    ints = ints.reshape(node_configs.shape[0], node_configs.shape[1], 3)\n",
    "    return ints\n",
    "\n",
    "\n",
    "def decompress_configs(node_configs):\n",
    "    ints = node_configs.astype(np.int32).reshape(-1)\n",
    "    vecs = int_to_vec(ints)\n",
    "    vecs = vecs.reshape(node_configs.shape[0], -1, 18) - 1\n",
    "    return vecs\n",
    "\n",
    "\n",
    "def test_compression(data, db=False):\n",
    "    org = data[\"node_config_feat\"].astype(np.int32)\n",
    "    comp = compress_configs(data[\"node_config_feat\"])\n",
    "    decomp = decompress_configs(comp)\n",
    "\n",
    "    if db:\n",
    "        print(org.shape, comp.shape, decomp.shape)\n",
    "        print(org[0, :2], comp[0, :2], decomp[0, :2], sep=\"\\n\")\n",
    "        print(get_obj_mbs(org), get_obj_mbs(comp), get_obj_mbs(decomp))\n",
    "    \n",
    "    res = (org == decomp).all()\n",
    "\n",
    "    assert res\n",
    "    assert round(get_obj_mbs(org) / get_obj_mbs(comp)) == 6\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/198 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [04:02<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading valid data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 25.00it/s]\n"
     ]
    }
   ],
   "source": [
    "dst_dir = root / f\"{collection}_compressed\" / ctype\n",
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    print(\"Loading {} data...\".format(split))\n",
    "    split_src_dir = root / collection / ctype / split\n",
    "    split_dst_dir = dst_dir / split\n",
    "    split_dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for npz_path in tqdm(list(split_src_dir.glob(\"*.npz\"))):\n",
    "        out_p = split_dst_dir / npz_path.name\n",
    "\n",
    "        if out_p.exists():\n",
    "            continue\n",
    "\n",
    "        data = dict(np.load(str(npz_path), allow_pickle=True))\n",
    "        # data = prune_graph(data)\n",
    "        \n",
    "        # if split == \"train\":\n",
    "        #     # assert test_dedup_configs(data)\n",
    "        #     data = dedup_configs(data)\n",
    "\n",
    "        if split == \"valid\":\n",
    "            best_idx = np.argsort(data[\"config_runtime\"])[:1000]\n",
    "            data[\"node_config_feat\"] = data[\"node_config_feat\"][best_idx]\n",
    "            data[\"config_runtime\"] = data[\"config_runtime\"][best_idx]\n",
    "\n",
    "        # assert test_compression(data)\n",
    "        data[\"node_config_feat\"] = compress_configs(data[\"node_config_feat\"])\n",
    "\n",
    "        # np.savez(split_dst_dir / npz_path.name, **data)\n",
    "        np.savez_compressed(split_dst_dir / npz_path.name, **data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_compression(data, db=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ints.reshape(data[\"node_config_feat\"].shape[0], data[\"node_config_feat\"].shape[1], 3).shape\n",
    "int_to_vec(ints).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vecs = data[\"node_config_feat\"][0, :, :6].astype(np.int32) + 1\n",
    "# (vecs == int_to_vec(vec_to_int(vecs))).all()\n",
    "\n",
    "# vecs = data[\"node_config_feat\"].reshape(-1, 3, 6).reshape(-1, 6).astype(np.int32) + 1\n",
    "\n",
    "\n",
    "\n",
    "vecs = data[\"node_config_feat\"].reshape(-1, 6).astype(np.int32) + 1\n",
    "ints = vec_to_int(vecs)\n",
    "res = int_to_vec(ints).reshape(data[\"node_config_feat\"].shape[0], -1, 18)\n",
    "\n",
    "(data[\"node_config_feat\"].astype(np.int32) + 1 == res).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(ints) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(data[\"node_config_feat\"].astype(np.int32)) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"node_config_feat\"][0, 0, :6].tolist()\n",
    "# sys.getsizeof(data[\"node_feat\"]) / 1e6\n",
    "\n",
    "reshaped_config_feat = data[\"node_config_feat\"].reshape(data[\"node_config_feat\"].shape[0], -1) + 2 # avoid zeros\n",
    "positional_array = np.random.random(reshaped_config_feat.shape[1])  # multiply each value by its position to avoid removing permutations by accident\n",
    "reshaped_values = (reshaped_config_feat * positional_array[None, :]).sum(1)\n",
    "is_equal_matrix = reshaped_values[None, :] == reshaped_values[:, None] # quadratic matrix of all pairwise equalities\n",
    "is_equal_matrix = np.tril(is_equal_matrix, -1) # only get diagonal to avoid remove twice\n",
    "to_remove_ids = np.unique(np.where(is_equal_matrix)[0])\n",
    "\n",
    "to_remove_ids\n",
    "\n",
    "# print(\"Removing {} duplicated node configs out of {}\".format(to_remove_ids.shape[0], data[\"node_config_feat\"].shape[0]))\n",
    "# data[\"config_runtime\"] = np.delete(data[\"config_runtime\"], to_remove_ids)\n",
    "# data[\"node_config_feat\"] = np.delete(data[\"node_config_feat\"], to_remove_ids, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_src_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/edu/code/google_fast_or_slow/data/npz_all/npz/layout/xla/default/train/ncf.2x2.fp32.npz\"\n",
    "data = np.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"node_config_feat\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_edge_index = data[\"edge_index\"][np.isin(data[\"edge_index\"], data[\"node_config_ids\"]).any(1)]\n",
    "\n",
    "in_node_ids = np.unique(in_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(data[\"node_config_ids\"]) - set(in_node_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100040 - 99668"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_config_feat = data[\"node_config_feat\"].reshape(data[\"node_config_feat\"].shape[0], -1)\n",
    "print(1)\n",
    "positional_array = (np.arange(reshaped_config_feat.shape[1]) + 1) # multiply each value by its position to avoid removing permutations by accident\n",
    "reshaped_values = (reshaped_config_feat * positional_array[None, :]).sum(1)\n",
    "print(2)\n",
    "is_equal_matrix = reshaped_values[None, :] == reshaped_values[:, None] # quadratic matrix of all pairwise equalities\n",
    "print(3)\n",
    "is_equal_matrix = np.tril(is_equal_matrix, -1) # only get diagonal to avoid remove twice\n",
    "print(4)\n",
    "to_remove_ids = np.unique(np.where(is_equal_matrix)[0])\n",
    "print(5)\n",
    "print(\"Removing {} duplicated node configs\".format(to_remove_ids.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dupplicated_node_configs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(100040 ** 2) * 4 / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dupplicated_node_configs(dict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"node_config_feat\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.delete(x, to_remove_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_equal_matrix.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 1, 2, 3, 3, 4, 7, 1, 2])\n",
    "m = x[None, :] == x[:, None]\n",
    "# remove 1,4, 7, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tril(m, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove_ids = np.unique(np.where(m)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.delete(x, to_remove_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(5304 ** 2) / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = prune_graph(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"edge_index\"].shape#[3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "in_node_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"node_feat\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(data[\"node_config_feat\"][:, :, 98], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k: data[k].shape for k in data.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique((data[\"node_config_feat\"].sum(2) != -18).sum(1), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot((data[\"node_config_feat\"].sum(2) != -18).sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((data[\"node_config_feat\"][0] != data[\"node_config_feat\"][3]).sum(1) > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100040 * 100040 * 1 / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"node_config_feat\"][i:i+1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((data[\"node_config_feat\"][i:i+1] != data[\"node_config_feat\"]).sum(2) > 0).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = 100\n",
    "bz = 100\n",
    "result = np.zeros((max_size, 100040), dtype=np.uint8)\n",
    "for i in tqdm(range(0, max_size, bz)):\n",
    "    result[i:i+bz] = ((data[\"node_config_feat\"][i:i+bz, None] != data[\"node_config_feat\"][None, ...]).sum(-1) > 0).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(result == 1).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(result == 0).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.min(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(result, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(result, 0.1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data[\"node_config_feat\"][0] != data[\"node_config_feat\"][0][1]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(data[\"node_feat\"][:, 22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_tpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
